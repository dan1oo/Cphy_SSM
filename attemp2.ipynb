{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a06f15",
   "metadata": {},
   "source": [
    "# Daniel's prevbit implementation (works well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3803c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training.generator_prevbit import make_train_test\n",
    "import numpy as np\n",
    "from SSM.hippo import hippo_legs, discretize_bilinear\n",
    "from SSM.helpers import sigmoid, binary_cross_entropy\n",
    "from SSM.model import SimpleSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0fd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "# Size of data matters alot, especially for how simple the task is. If the training data is very large, then the model will learn it within one epoch and the average loss will be small even on the first pass\n",
    "x_train, y_train, x_test, y_test = make_train_test(\n",
    "    n_train=100,\n",
    "    n_test=10,\n",
    "    T=10,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b5b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleSSM(state_dim=8, input_dim=1, output_dim=1)\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b9ae2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual BCE on first sequence: 0.693127495054777\n",
      "loss_and_grads loss: 0.693127495054777\n"
     ]
    }
   ],
   "source": [
    "from SSM.helpers import sigmoid  # or your sigmoid\n",
    "\n",
    "u = x_train[0]            # (T,1)\n",
    "t = y_train[0]            # (T,1)\n",
    "logits, _ = model.forward(u)\n",
    "probs = sigmoid(logits)\n",
    "\n",
    "eps = 1e-8\n",
    "loss_manual = -np.mean(\n",
    "    t * np.log(probs + eps) +\n",
    "    (1 - t) * np.log(1 - probs + eps)\n",
    ")\n",
    "print(\"manual BCE on first sequence:\", loss_manual)\n",
    "\n",
    "loss, _ = model.loss_and_grads(u, t)\n",
    "print(\"loss_and_grads loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ef5d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | avg loss = 0.6879106509364754\n",
      "epoch 1 | avg loss = 0.683121272966656\n",
      "epoch 2 | avg loss = 0.6769088588642727\n",
      "epoch 3 | avg loss = 0.6684853640239835\n",
      "epoch 4 | avg loss = 0.6570768769677479\n",
      "epoch 5 | avg loss = 0.6420406052729862\n",
      "epoch 6 | avg loss = 0.6220244264588835\n",
      "epoch 7 | avg loss = 0.5932047998161526\n",
      "epoch 8 | avg loss = 0.5497263027419215\n",
      "epoch 9 | avg loss = 0.4878240095192452\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(x_train.shape[0]):\n",
    "        u = x_train[i]      # shape (T,1)\n",
    "        tgt = y_train[i]    # shape (T,1)\n",
    "\n",
    "        loss, grads = model.loss_and_grads(u, tgt)\n",
    "        \n",
    "\n",
    "        \n",
    "        model.step(grads, lr=learning_rate)\n",
    "        epoch_loss += loss\n",
    "\n",
    "    print(f\"epoch {epoch} | avg loss = {epoch_loss / x_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30a8ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of y_train: 0.529\n",
      "min target: 0.0 max target: 1.0\n",
      "mean target over all train data: 0.529\n",
      "input:   [1, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "target:  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "baseline constant-p loss: 2.4408682028173887\n"
     ]
    }
   ],
   "source": [
    "# Testing ERror\n",
    "print(\"mean of y_train:\", y_train.mean())\n",
    "print(\"min target:\", y_train.min(), \"max target:\", y_train.max())\n",
    "print(\"mean target over all train data:\", y_train.mean())\n",
    "\n",
    "u = x_train[0].reshape(-1)\n",
    "t = y_train[0].reshape(-1)\n",
    "print(\"input:  \", u.astype(int).tolist())\n",
    "print(\"target: \", t.astype(int).tolist())\n",
    "\n",
    "import numpy as np\n",
    "eps = 1e-8\n",
    "p = 0.01\n",
    "y = y_train.reshape(-1)   # flatten all targets\n",
    "\n",
    "baseline_loss = -np.mean(\n",
    "    y * np.log(p + eps) + (1 - y) * np.log(1 - p + eps)\n",
    ")\n",
    "\n",
    "print(\"baseline constant-p loss:\", baseline_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15509aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44985656218869013\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "N = x_test.shape[0]\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "total_bits = 0\n",
    "\n",
    "for i in range(N):\n",
    "    u = x_test[i]      # (T, 1)\n",
    "    tgt = y_test[i]    # (T, 1)\n",
    "\n",
    "    # forward pass only (no grads)\n",
    "    logits, _ = model.forward(u)\n",
    "\n",
    "    # loss for this sequence\n",
    "    loss = binary_cross_entropy(logits, tgt)\n",
    "    total_loss += loss\n",
    "\n",
    "    # compute accuracy for this sequence\n",
    "    probs = sigmoid(logits)\n",
    "    preds = (probs > 0.5).astype(int)   # threshold at 0.5\n",
    "    total_correct += (preds == tgt).sum()\n",
    "    total_bits += tgt.size\n",
    "\n",
    "avg_loss = total_loss / N\n",
    "accuracy = total_correct / total_bits\n",
    "\n",
    "print(avg_loss)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
